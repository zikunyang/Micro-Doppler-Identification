{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于深度学习的无人机微多普勒识别（监督式学习）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import math\n",
    "import torch.distributions as tdis\n",
    "import dill\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset,RandomSampler,BatchSampler,DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （1）训练集的读取和处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##定义txt读取函数\n",
    "def ReadTxtName(rootdir):                    \n",
    "    lines = []\n",
    "    with open(rootdir, 'r') as file_to_read:\n",
    "        while True:\n",
    "            line = file_to_read.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            line = line.strip('\\n')\n",
    "            lines.append(line)\n",
    "    return lines\n",
    "\n",
    "##读取data1训练集\n",
    "file      = r'./data1.txt'    \n",
    "dataset1  = ReadTxtName(file)\n",
    "\n",
    "dataset1[1145] = dataset1[1144]\n",
    "dataset1[2681] = dataset1[2680]\n",
    "dataset1[3192] = dataset1[3191]\n",
    "dataset1[3255] = dataset1[3251]\n",
    "dataset1[3787] = dataset1[3786]\n",
    "\n",
    "##将data1的文本数据存入数组并转化为数值数据\n",
    "B = [0]*4000\n",
    "for i in range (4000):\n",
    "    B[i]=[0]*256*40+[0]\n",
    "for i in range (4000):\n",
    "    B[i][256*40]=dataset1[i][256*40*4]\n",
    "    for j in range (len(B[i])-1):\n",
    "        B[i][j]=dataset1[i][4*j]+dataset1[i][4*j+1]+dataset1[i][4*j+2]\n",
    "\n",
    "##C为训练集，共4000个数据，前一半为单旋翼，后一半为四旋翼，每一个数据最后一位为0或1，表示单旋翼或者四旋翼类型        \n",
    "C = [0]*4000\n",
    "for i in range (4000):\n",
    "    C[i]=[0]*256*40+[0]\n",
    "    \n",
    "for i in range (len(B)):\n",
    "    for j in range (len(B[i])):\n",
    "        C[i][j]=float(B[i][j])\n",
    "\n",
    "##将训练集转换为Tensor类型以供机器学习\n",
    "train_set = torch.tensor(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （2）测试集的读取和处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##读取data2测试集\n",
    "file      = r'./data2.txt'    \n",
    "dataset2  = ReadTxtName(file)\n",
    "\n",
    "dataset2[2765] = dataset2[2764]\n",
    "dataset2[2960] = dataset2[2959]\n",
    "dataset2[3489] = dataset2[3488]\n",
    "\n",
    "##将data2的文本数据存入数组并转化为数值数据\n",
    "D = [0]*4000\n",
    "for i in range (4000):\n",
    "    D[i]=[0]*256*40+[0]\n",
    "for i in range (4000):\n",
    "    D[i][256*40]=dataset2[i][256*40*4]\n",
    "    for j in range (len(D[i])-1):\n",
    "        D[i][j]=dataset2[i][4*j]+dataset2[i][4*j+1]+dataset2[i][4*j+2]\n",
    "        \n",
    "##E为测试集，共4000个数据，前一半为单旋翼，后一半为四旋翼，每一个数据最后一位为0或1，表示单旋翼或者四旋翼类型        \n",
    "E = [0]*4000\n",
    "for i in range (4000):\n",
    "    E[i]=[0]*256*40+[0]\n",
    "    \n",
    "for i in range (len(D)):\n",
    "    for j in range (len(D[i])):\n",
    "        E[i][j]=float(D[i][j])\n",
    "    \n",
    "##将测试集转换为Tensor类型以供机器学习\n",
    "test_set = torch.tensor(E)\n",
    "\n",
    "file      = r'./MD.txt'    \n",
    "dataset  = ReadTxtName(file)\n",
    "F = [0]*200\n",
    "for i in range (200):\n",
    "    F[i]=[0]*256*40+[0]\n",
    "for i in range (len(F)):\n",
    "    F[i][256*40]=dataset[i][256*40*4]\n",
    "    for j in range (len(F[i])-1):\n",
    "        F[i][j]=dataset[i][4*j]+dataset[i][4*j+1]+dataset[i][4*j+2]\n",
    "G= [0]*200\n",
    "for i in range (200):\n",
    "    G[i]=[0]*256*40+[0]\n",
    "    \n",
    "for i in range (len(F)):\n",
    "    for j in range (len(F[i])):\n",
    "        G[i][j]=float(F[i][j])\n",
    "        \n",
    "test2_set = torch.tensor(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （3）定义深度学习函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##这两个函数用于卷积网络末尾的数据维度处理使其符合输入输出格式\n",
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n",
    "\n",
    "\n",
    "def preprocess(x):\n",
    "    return x.view(-1, 1, 256, 40)\n",
    "\n",
    "##深度学习函数\n",
    "def MDClassifier(sample, num_epochs=300, batch_size=512, model=None, lrate=0.0005):    \n",
    "    \n",
    "    ##sample的前256x40位为其微多普勒图像，最后一位为其所属类型，将这两个数据分别设为X和Y\n",
    "    counter   = sample.shape[1] - 1\n",
    "    X         = sample[:,:counter]        \n",
    "    Y         = sample[:,counter:]             \n",
    "    \n",
    "    \n",
    "    ##建立深度神经网络\n",
    "    if not model:\n",
    "        ##model1为多层深度卷积网络\n",
    "        model1 = nn.Sequential(\n",
    "                    Lambda(preprocess),\n",
    "                    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Conv2d(16, 1, kernel_size=3, stride=2, padding=1),\n",
    "                    nn.ReLU(),\n",
    "                    nn.AvgPool2d(2),\n",
    "                    Lambda(lambda x: x.view(x.size(0), -1)),\n",
    "                )\n",
    "        \n",
    "        ##model2为多层深度线性网络\n",
    "        model2 = nn.Sequential(       \n",
    "                    nn.Linear(32, 64),\n",
    "                    nn.Tanh(),\n",
    "                    nn.Linear(64, 128),\n",
    "                    nn.Tanh(),\n",
    "                    nn.Linear(128, 64),\n",
    "                    nn.Tanh(),\n",
    "                    nn.Linear(64, 32),\n",
    "                    nn.Tanh(),\n",
    "                    nn.Linear(32, 16), \n",
    "                    nn.Tanh(),\n",
    "                    nn.Linear(16, 1),                    \n",
    "                    nn.Sigmoid()\n",
    "                )\n",
    "    \n",
    "\n",
    "    ##Optimizer中使用Adam算法    \n",
    "    opt1  = optim.Adam(model1.parameters(), lr=lrate)\n",
    "    opt2  = optim.Adam(model2.parameters(), lr=lrate)\n",
    "    td    = TensorDataset(X, Y)\n",
    "    epoch = 0\n",
    "\n",
    "    ##开始训练\n",
    "    while epoch < num_epochs: \n",
    "        \n",
    "        ##每个epoch完成后shuffle数据\n",
    "        for x, y in DataLoader(td, batch_size, shuffle=True, drop_last=True):  \n",
    "            \n",
    "            ##重制梯度\n",
    "            opt1.zero_grad()\n",
    "            opt2.zero_grad()\n",
    "            \n",
    "            ##神经网络计算，LinearOut为最终结果\n",
    "            CONVOut   = model1(x)\n",
    "            LinearOut = model2(CONVOut)  \n",
    "            \n",
    "            ##计算网络输出和标准答案的差距\n",
    "            loss = ((LinearOut - y)**2).mean()\n",
    "            \n",
    "            ##计算梯度\n",
    "            loss.backward()\n",
    "            \n",
    "            ##更新网络权重\n",
    "            opt1.step()\n",
    "            opt2.step()\n",
    "    \n",
    "        epoch += 1\n",
    "        \n",
    "        if epoch%10 == 0:\n",
    "            print(loss)\n",
    "            \n",
    "    ##函数返回两个训练完成的神经网络      \n",
    "    return model1, model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##训练网络\n",
    "net1, net2 = MDClassifier(train_set[1100:2900])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##保存网络以便今后使用\n",
    "torch.save(net1, 'SupervisedConv.pth', pickle_module=dill)\n",
    "torch.save(net2, 'SupervisedLinear.pth', pickle_module=dill)\n",
    "\n",
    "##读取网络\n",
    "CONV   = torch.load('SupervisedConv.pth', pickle_module=dill)\n",
    "Linear = torch.load('SupervisedLinear.pth', pickle_module=dill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = E[0:200]+E[3800:4000]\n",
    "print(len(H))\n",
    "test3_set = torch.tensor(H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 网络的ROC曲线测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##定义计算FPR、TPR及准确率的函数\n",
    "def PR(test, cov = CONV, lin = Linear, SH = 0.5):\n",
    "    P      = 0\n",
    "    F      = 0    \n",
    "    countP = 0\n",
    "    countF = 0\n",
    "    \n",
    "    for i in range (len(test)):\n",
    "        if (lin(cov(test[i][0:10240]))-1)**2 < SH:\n",
    "            countP += 1\n",
    "            if i < 100:\n",
    "                P += 1\n",
    "            if i > 99:\n",
    "                F += 1\n",
    "        else:\n",
    "            if i > 99:\n",
    "                countF += 1\n",
    "                \n",
    "    TPR      = P / 109    \n",
    "    FPR      = F / 109\n",
    "    accuracy = (P + countF) / 218\n",
    "    \n",
    "    return TPR, FPR, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##测试训练集\n",
    "TPR = []\n",
    "FPR = []\n",
    "accuracy = []\n",
    "for i in range (100):\n",
    "    a, b, c = PR(test2_set, SH=i*0.01)\n",
    "    TPR.append(a)\n",
    "    FPR.append(b)\n",
    "    accuracy.append(c)\n",
    "    \n",
    "##ROC曲线作图\n",
    "plt.plot(FPR,TPR)\n",
    "\n",
    "##计算ROC的AUC面积\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "roc_auc = auc(FPR,TPR)\n",
    "print(roc_auc)\n",
    "\n",
    "##结果保存到csv文件中\n",
    "import csv\n",
    "import pandas as pd\n",
    "TPRset = pd.DataFrame(data=TPR)\n",
    "TPRset.to_csv('TPR.csv',encoding='gbk')\n",
    "FPRset = pd.DataFrame(data=FPR)\n",
    "FPRset.to_csv('FPR.csv',encoding='gbk')\n",
    "accset = pd.DataFrame(data=accuracy)\n",
    "accset.to_csv('accuracy.csv',encoding='gbk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
